#!/usr/bin/env python3
"""
Cycle OKE node pool workers by replacing their boot volumes.

The OCI documentation describes the behaviour where updating a node pool only
adjusts configuration for new nodes. Existing workers must be cycled (boot
volume replaced) to pick up the new image or Kubernetes version. This command
drives that workflow using the HTML report generated by ``oke_version_report``.
"""

from __future__ import annotations

import argparse
import logging
import time
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, Iterable, List, Optional, Sequence, Tuple

from rich.console import Console
from rich.logging import RichHandler

from oci import exceptions as oci_exceptions
from oci.container_engine.models import (
    NodeEvictionSettings,
    ReplaceBootVolumeClusterNodeDetails,
)

from oci_client.models import OKEClusterInfo, OKENodePoolInfo
from oci_client.utils.display import display_warning
from oci_client.utils.session import create_oci_client, setup_session_token
from oke_upgrade import ReportCluster, load_clusters_from_report

console = Console()
logger = logging.getLogger(__name__)

TERMINAL_WORK_REQUEST_STATES = {"SUCCEEDED", "FAILED", "CANCELED"}
SKIP_NODE_STATES = {"DELETED", "DELETING"}


@dataclass
class NodeCycleResult:
    """Outcome for cycling a single node."""

    entry: ReportCluster
    node_pool_id: str
    node_pool_name: str
    node_id: str
    node_name: str
    status: str
    work_request_id: Optional[str]
    skipped: bool = False
    error: Optional[str] = None

    @property
    def success(self) -> bool:
        return (
            not self.skipped
            and self.error is None
            and self.status.upper() in {"SUCCEEDED", "IN_PROGRESS"}
        )


def _build_filters(args: argparse.Namespace) -> Dict[str, List[str]]:
    filters: Dict[str, List[str]] = {}
    if args.project:
        filters["project"] = [args.project]
    if args.stage:
        filters["stage"] = [args.stage]
    if args.region:
        filters["region"] = [args.region]
    if args.cluster:
        filters["cluster"] = [args.cluster]
    if args.node_pool:
        filters["node_pool"] = args.node_pool
    if args.node:
        filters["node"] = args.node
    return filters


def _entry_matches_filters(entry: ReportCluster, filters: Dict[str, List[str]]) -> bool:
    project_filter = filters.get("project")
    stage_filter = filters.get("stage")
    region_filter = filters.get("region")
    cluster_filter = filters.get("cluster")

    if project_filter and entry.project not in project_filter:
        return False
    if stage_filter and entry.stage not in stage_filter:
        return False
    if region_filter and entry.region not in region_filter:
        return False
    if cluster_filter and entry.cluster_ocid not in cluster_filter and entry.cluster_name not in cluster_filter:
        return False
    return True


def _node_pool_matches_filters(node_pool: OKENodePoolInfo, filters: Dict[str, List[str]]) -> bool:
    node_pool_filter = filters.get("node_pool")
    if not node_pool_filter:
        return True
    return node_pool.node_pool_id in node_pool_filter or node_pool.name in node_pool_filter


def _node_matches_filters(node: Any, filters: Dict[str, List[str]]) -> bool:
    node_filter = filters.get("node")
    if not node_filter:
        return True
    node_id = getattr(node, "id", "")
    node_name = getattr(node, "name", "")
    return any(candidate in {node_id, node_name} for candidate in node_filter)


def _resolve_cluster_details(client: Any, cluster_id: str) -> OKEClusterInfo:
    """
    Retrieve cluster details either via the dedicated helper or by directly querying
    the Container Engine client (maintains compatibility with older client versions).
    """
    if hasattr(client, "get_oke_cluster"):
        return client.get_oke_cluster(cluster_id)  # type: ignore[attr-defined]

    ce_client = getattr(client, "container_engine_client", None)
    if ce_client is None:
        raise AttributeError("OCI client does not expose container_engine_client")

    cluster = ce_client.get_cluster(cluster_id).data
    available_upgrades_attr = getattr(cluster, "available_kubernetes_upgrades", None)
    if available_upgrades_attr is None:
        available_upgrades_attr = getattr(cluster, "available_upgrades", None)
    available_upgrades = list(available_upgrades_attr or [])

    return OKEClusterInfo(
        cluster_id=cluster_id,
        name=getattr(cluster, "name", cluster_id),
        kubernetes_version=getattr(cluster, "kubernetes_version", None),
        lifecycle_state=getattr(cluster, "lifecycle_state", None),
        compartment_id=getattr(cluster, "compartment_id", None),
        available_upgrades=available_upgrades,
    )


def _list_node_pools(client: Any, cluster_id: str, compartment_id: Optional[str]) -> List[OKENodePoolInfo]:
    """Retrieve node pools either via client helper or directly from the Container Engine API."""
    if hasattr(client, "list_node_pools"):
        return client.list_node_pools(cluster_id, compartment_id)  # type: ignore[attr-defined]

    ce_client = getattr(client, "container_engine_client", None)
    if ce_client is None:
        raise AttributeError("OCI client does not expose container_engine_client")

    request_kwargs: Dict[str, Any] = {"cluster_id": cluster_id}
    if compartment_id:
        request_kwargs["compartment_id"] = compartment_id

    response = ce_client.list_node_pools(**request_kwargs)
    data = getattr(response, "data", []) or []

    node_pools: List[OKENodePoolInfo] = []
    for pool in data:
        node_pool_id = getattr(pool, "id", None)
        if not node_pool_id:
            continue
        node_pools.append(
            OKENodePoolInfo(
                node_pool_id=node_pool_id,
                name=getattr(pool, "name", node_pool_id),
                kubernetes_version=getattr(pool, "kubernetes_version", None),
                lifecycle_state=getattr(pool, "lifecycle_state", None),
            )
        )
    return node_pools


def _fetch_node_pool_details(client: Any, node_pool_id: str) -> Any:
    ce_client = getattr(client, "container_engine_client", None)
    if ce_client is None:
        raise AttributeError("OCI client does not expose container_engine_client")
    return ce_client.get_node_pool(node_pool_id).data


def _collect_work_request_errors(ce_client: Any, work_request_id: str) -> List[str]:
    errors: List[str] = []
    try:
        response = ce_client.list_work_request_errors(work_request_id)
    except oci_exceptions.ServiceError as exc:
        logger.error("Failed to fetch errors for work request %s: %s", work_request_id, exc.message)
        return errors

    for item in getattr(response, "data", []) or []:
        message = getattr(item, "message", None)
        timestamp = getattr(item, "timestamp", None)
        formatted = f"{timestamp}: {message}" if timestamp else (message or "Unknown error")
        if formatted:
            errors.append(formatted)
            logger.error("Work request %s error: %s", work_request_id, formatted)
    return errors


def _wait_for_work_request(
    ce_client: Any,
    work_request_id: str,
    poll_seconds: int,
) -> Tuple[str, List[str]]:
    """Poll the Container Engine work request until it completes."""
    while True:
        try:
            response = ce_client.get_work_request(work_request_id)
        except oci_exceptions.ServiceError as exc:
            logger.error("Error querying work request %s: %s", work_request_id, exc.message)
            return "FAILED", [exc.message]

        work_request = response.data
        status = getattr(work_request, "status", "UNKNOWN") or "UNKNOWN"
        percent = getattr(work_request, "percent_complete", None)
        operation = getattr(work_request, "operation_type", "UNKNOWN")
        logger.info(
            "Work request %s status=%s operation=%s percent=%s",
            work_request_id,
            status,
            operation,
            percent,
        )

        if status in TERMINAL_WORK_REQUEST_STATES:
            if status == "SUCCEEDED":
                return status, []
            errors = _collect_work_request_errors(ce_client, work_request_id)
            return status or "FAILED", errors

        time.sleep(poll_seconds)


def _cycle_node(
    entry: ReportCluster,
    node_pool: OKENodePoolInfo,
    node: Any,
    client: Any,
    *,
    grace_period: str,
    force_after_grace: bool,
    poll_seconds: int,
    wait_for_completion: bool,
    dry_run: bool,
) -> NodeCycleResult:
    node_id = getattr(node, "id", None)
    node_name = getattr(node, "name", node_id or "unknown")
    lifecycle_state = (getattr(node, "lifecycle_state", None) or "").upper()

    if not node_id:
        message = f"Node pool {node_pool.name} contains a node without an OCID; skipping."
        display_warning(message)
        return NodeCycleResult(
            entry=entry,
            node_pool_id=node_pool.node_pool_id,
            node_pool_name=node_pool.name,
            node_id="N/A",
            node_name=node_name,
            status="SKIPPED",
            work_request_id=None,
            skipped=True,
            error=message,
        )

    if lifecycle_state in SKIP_NODE_STATES:
        logger.info(
            "Skipping node %s (%s) in pool %s because lifecycle_state=%s",
            node_name,
            node_id,
            node_pool.node_pool_id,
            lifecycle_state,
        )
        return NodeCycleResult(
            entry=entry,
            node_pool_id=node_pool.node_pool_id,
            node_pool_name=node_pool.name,
            node_id=node_id,
            node_name=node_name,
            status=lifecycle_state or "SKIPPED",
            work_request_id=None,
            skipped=True,
        )

    if dry_run:
        logger.info(
            "[DRY RUN] Would replace boot volume for node %s (%s) in pool %s (%s) within cluster %s.",
            node_name,
            node_id,
            node_pool.name,
            node_pool.node_pool_id,
            entry.cluster_name,
        )
        return NodeCycleResult(
            entry=entry,
            node_pool_id=node_pool.node_pool_id,
            node_pool_name=node_pool.name,
            node_id=node_id,
            node_name=node_name,
            status="DRY_RUN",
            work_request_id=None,
            skipped=True,
        )

    ce_client = getattr(client, "container_engine_client", None)
    if ce_client is None:
        message = "OCI client does not expose container_engine_client"
        logger.error(message)
        return NodeCycleResult(
            entry=entry,
            node_pool_id=node_pool.node_pool_id,
            node_pool_name=node_pool.name,
            node_id=node_id,
            node_name=node_name,
            status="FAILED",
            work_request_id=None,
            error=message,
        )

    eviction_settings = NodeEvictionSettings(
        eviction_grace_duration=grace_period,
        is_force_action_after_grace_duration=force_after_grace,
    )
    details = ReplaceBootVolumeClusterNodeDetails(node_eviction_settings=eviction_settings)

    logger.info(
        "Replacing boot volume for node %s (%s) in pool %s (%s) within cluster %s (%s).",
        node_name,
        node_id,
        node_pool.name,
        node_pool.node_pool_id,
        entry.cluster_name,
        entry.cluster_ocid,
    )

    try:
        response = ce_client.replace_boot_volume_cluster_node(
            entry.cluster_ocid,
            node_id,
            details,
        )
    except oci_exceptions.ServiceError as exc:
        logger.error(
            "Failed to replace boot volume for node %s (%s) in pool %s: %s",
            node_name,
            node_id,
            node_pool.node_pool_id,
            exc.message,
        )
        return NodeCycleResult(
            entry=entry,
            node_pool_id=node_pool.node_pool_id,
            node_pool_name=node_pool.name,
            node_id=node_id,
            node_name=node_name,
            status="FAILED",
            work_request_id=None,
            error=exc.message,
        )

    work_request_id = response.headers.get("opc-work-request-id")
    if not wait_for_completion:
        status = "IN_PROGRESS" if work_request_id else "UNKNOWN"
        console.print(
            f"[bold green]âœ“[/bold green] Cycle triggered for node [cyan]{node_name}[/cyan] "
            f"({node_id}). Work request: [magenta]{work_request_id or 'N/A'}[/magenta]"
        )
        return NodeCycleResult(
            entry=entry,
            node_pool_id=node_pool.node_pool_id,
            node_pool_name=node_pool.name,
            node_id=node_id,
            node_name=node_name,
            status=status,
            work_request_id=work_request_id,
        )

    if not work_request_id:
        message = "OCI did not return a work request ID."
        logger.error(message)
        return NodeCycleResult(
            entry=entry,
            node_pool_id=node_pool.node_pool_id,
            node_pool_name=node_pool.name,
            node_id=node_id,
            node_name=node_name,
            status="FAILED",
            work_request_id=None,
            error=message,
        )

    status, errors = _wait_for_work_request(ce_client, work_request_id, poll_seconds)
    if errors:
        error_message = "; ".join(errors)
        console.print(
            f"[bold red]âœ—[/bold red] Cycle for node [cyan]{node_name}[/cyan] ({node_id}) "
            f"ended with status [red]{status}[/red]."
        )
        return NodeCycleResult(
            entry=entry,
            node_pool_id=node_pool.node_pool_id,
            node_pool_name=node_pool.name,
            node_id=node_id,
            node_name=node_name,
            status=status,
            work_request_id=work_request_id,
            error=error_message,
        )

    console.print(
        f"[bold green]âœ“[/bold green] Cycle completed for node [cyan]{node_name}[/cyan] "
        f"({node_id}). Work request: [magenta]{work_request_id}[/magenta]"
    )
    return NodeCycleResult(
        entry=entry,
        node_pool_id=node_pool.node_pool_id,
        node_pool_name=node_pool.name,
        node_id=node_id,
        node_name=node_name,
        status=status,
        work_request_id=work_request_id,
    )


def perform_node_cycles(
    entries: Sequence[ReportCluster],
    *,
    requested_version: Optional[str],
    filters: Dict[str, List[str]],
    grace_period: str,
    force_after_grace: bool,
    poll_seconds: int,
    wait_for_completion: bool,
    dry_run: bool,
) -> List[NodeCycleResult]:
    results: List[NodeCycleResult] = []
    clients: Dict[Tuple[str, str, str], Any] = {}

    for entry in entries:
        if filters and not _entry_matches_filters(entry, filters):
            logger.debug(
                "Skipping cluster %s due to filters project=%s stage=%s region=%s cluster_filter=%s node_pool_filter=%s node_filter=%s",
                entry.cluster_name,
                filters.get("project"),
                filters.get("stage"),
                filters.get("region"),
                filters.get("cluster"),
                filters.get("node_pool"),
                filters.get("node"),
            )
            continue

        client_key = (entry.project, entry.stage, entry.region)
        if client_key not in clients:
            profile_name = setup_session_token(entry.project, entry.stage, entry.region)
            client = create_oci_client(entry.region, profile_name)
            if not client:
                message = (
                    f"Failed to initialize OCI client for {entry.project}/{entry.stage} in {entry.region}."
                )
                display_warning(message)
                results.append(
                    NodeCycleResult(
                        entry=entry,
                        node_pool_id="N/A",
                        node_pool_name="N/A",
                        node_id="N/A",
                        node_name="N/A",
                        status="FAILED",
                        work_request_id=None,
                        error=message,
                    )
                )
                continue
            clients[client_key] = client

        client = clients[client_key]
        try:
            cluster_info = _resolve_cluster_details(client, entry.cluster_ocid)
        except Exception as exc:  # pragma: no cover - defensive guard
            message = (
                f"Failed to resolve cluster details for {entry.cluster_name} "
                f"({entry.cluster_ocid}) in {entry.region}: {exc}"
            )
            display_warning(message)
            results.append(
                NodeCycleResult(
                    entry=entry,
                    node_pool_id="N/A",
                    node_pool_name="N/A",
                    node_id="N/A",
                    node_name="N/A",
                    status="FAILED",
                    work_request_id=None,
                    error=str(exc),
                )
            )
            continue

        if cluster_info.available_upgrades:
            display_warning(
                f"Cluster {entry.cluster_name} ({entry.cluster_ocid}) still lists available control "
                "plane upgrades. Complete the control plane upgrade and regenerate the report before cycling nodes."
            )

        if requested_version and cluster_info.kubernetes_version and requested_version != cluster_info.kubernetes_version:
            display_warning(
                f"Cluster {entry.cluster_name} ({entry.cluster_ocid}) control plane version "
                f"{cluster_info.kubernetes_version} does not match requested version {requested_version}. "
                "Continuing with node cycling."
            )

        try:
            node_pools = _list_node_pools(client, entry.cluster_ocid, cluster_info.compartment_id)
        except Exception as exc:  # pragma: no cover - defensive guard
            message = (
                f"Failed to list node pools for cluster {entry.cluster_name} "
                f"({entry.cluster_ocid}): {exc}"
            )
            display_warning(message)
            results.append(
                NodeCycleResult(
                    entry=entry,
                    node_pool_id="N/A",
                    node_pool_name="N/A",
                    node_id="N/A",
                    node_name="N/A",
                    status="FAILED",
                    work_request_id=None,
                    error=str(exc),
                )
            )
            continue

        filtered_node_pools = [
            node_pool for node_pool in node_pools if _node_pool_matches_filters(node_pool, filters)
        ]
        if not filtered_node_pools:
            logger.info(
                "No node pools matched filters for cluster %s (%s).",
                entry.cluster_name,
                entry.cluster_ocid,
            )
            continue

        for node_pool in filtered_node_pools:
            try:
                node_pool_details = _fetch_node_pool_details(client, node_pool.node_pool_id)
            except Exception as exc:  # pragma: no cover - defensive guard
                message = (
                    f"Failed to fetch node pool {node_pool.name} ({node_pool.node_pool_id}) details: {exc}"
                )
                display_warning(message)
                results.append(
                    NodeCycleResult(
                        entry=entry,
                        node_pool_id=node_pool.node_pool_id,
                        node_pool_name=node_pool.name,
                        node_id="N/A",
                        node_name="N/A",
                        status="FAILED",
                        work_request_id=None,
                        error=str(exc),
                    )
                )
                continue

            nodes = getattr(node_pool_details, "nodes", None) or []
            if not nodes:
                console.print(
                    f"[dim]Node pool [cyan]{node_pool.name}[/cyan] "
                    f"({node_pool.node_pool_id}) has no worker nodes; skipping.[/dim]"
                )
                continue

            for node in nodes:
                if not _node_matches_filters(node, filters):
                    continue
                result = _cycle_node(
                    entry,
                    node_pool,
                    node,
                    client,
                    grace_period=grace_period,
                    force_after_grace=force_after_grace,
                    poll_seconds=poll_seconds,
                    wait_for_completion=wait_for_completion,
                    dry_run=dry_run,
                )
                results.append(result)

    return results


def _summarize(results: Iterable[NodeCycleResult]) -> Tuple[int, int, int]:
    initiated = sum(1 for item in results if item.success)
    failures = sum(1 for item in results if not item.skipped and not item.success)
    skipped = sum(1 for item in results if item.skipped)
    return initiated, skipped, failures


def configure_logging(verbose: bool = False) -> None:
    logging.basicConfig(
        level=logging.DEBUG if verbose else logging.INFO,
        format="%(message)s",
        handlers=[RichHandler(rich_tracebacks=True)],
    )


def parse_arguments() -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        description="Cycle OKE node pools to replace worker boot volumes based on an HTML report.",
    )
    parser.add_argument("report_path", help="Path to the HTML report generated by oke_version_report.")
    parser.add_argument("--project", help="Only cycle node pools for this project.")
    parser.add_argument("--stage", help="Only cycle node pools for this stage.")
    parser.add_argument("--region", help="Only cycle node pools in this region.")
    parser.add_argument(
        "--cluster",
        help="Only cycle node pools for the cluster matching this name or OCID.",
    )
    parser.add_argument(
        "--node-pool",
        action="append",
        help="Only cycle node pools matching this name or OCID. Can be provided multiple times.",
    )
    parser.add_argument(
        "--node",
        action="append",
        help="Only cycle specific nodes by name or OCID. Can be provided multiple times.",
    )
    parser.add_argument(
        "--grace-period",
        default="PT30M",
        help="Eviction grace period in ISO-8601 duration format (default: PT30M).",
    )
    parser.add_argument(
        "--force-after-grace",
        action="store_true",
        help="Force deletion after the grace period elapses.",
    )
    parser.add_argument(
        "--poll-seconds",
        type=int,
        default=30,
        help="Polling interval (seconds) when waiting on work requests (default: 30).",
    )
    parser.add_argument(
        "--no-wait",
        action="store_true",
        help="Do not wait for work requests to complete (fire-and-forget).",
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="Show planned node cycles without calling OCI APIs.",
    )
    parser.add_argument(
        "--verbose",
        action="store_true",
        help="Enable debug logging.",
    )
    parser.add_argument(
        "--target-version",
        help="Optional Kubernetes version to validate against the control plane before cycling.",
    )
    return parser.parse_args()


def main() -> int:
    args = parse_arguments()
    configure_logging(verbose=args.verbose)

    report_path = Path(args.report_path).expanduser().resolve()
    if not report_path.exists():
        console.print(f"[bold red]âœ— Report not found:[/bold red] {report_path}")
        return 1

    entries = load_clusters_from_report(report_path)
    if not entries:
        console.print("[bold red]âœ— No clusters found in the provided report.[/bold red]")
        return 1

    filters = _build_filters(args)

    console.print("ðŸš€ Initiating OKE node cycling workflow...")
    console.print(f"ðŸ“„ Using report: {report_path}")

    results = perform_node_cycles(
        entries,
        requested_version=args.target_version,
        filters=filters,
        grace_period=args.grace_period,
        force_after_grace=args.force_after_grace,
        poll_seconds=args.poll_seconds,
        wait_for_completion=not args.no_wait,
        dry_run=args.dry_run,
    )

    initiated, skipped, failures = _summarize(results)
    console.print(
        f"Summary: initiated {initiated} cycle(s); {skipped} skipped; {failures} failure(s)."
    )

    return 0 if failures == 0 else 1


if __name__ == "__main__":  # pragma: no cover
    raise SystemExit(main())
